{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-02T08:11:43.583813Z",
     "start_time": "2019-07-02T08:09:38.183206Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import re\n",
    "import math\n",
    "import requests as re\n",
    "import matplotlib.pyplot as plt\n",
    "from operator import add\n",
    "from keras import optimizers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, f1_score, roc_auc_score, confusion_matrix, accuracy_score\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras.utils import to_categorical, np_utils\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/job:localhost/replica:0/task:0/device:GPU:0']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-02T08:18:55.882131Z",
     "start_time": "2019-07-02T08:18:52.050647Z"
    }
   },
   "outputs": [],
   "source": [
    "Data = pd.read_csv(\"CleanData.csv\").drop(columns = [\"Unnamed: 0\",\"LyricsOriginal\"])\n",
    "Data[\"TrackArtist\"] = Data.Track +\" By \"+ Data.Artist1\n",
    "Data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artists Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-01T10:10:33.549999Z",
     "start_time": "2019-07-01T10:10:33.408098Z"
    }
   },
   "outputs": [],
   "source": [
    "ArtistAll = Data.Artist2[Data.Artist2!=\"Nan\"].value_counts()[0:10]\n",
    "ArtistTop10 = Data.Artist2[(Data.Artist2!=\"Nan\") & (Data.Rank <= 10)].value_counts()[0:10]\n",
    "ArtistTop3 = Data.Artist2[(Data.Artist2!=\"Nan\") & (Data.Rank <= 3)].value_counts()[0:10]\n",
    "ArtistTop1 = Data.Artist2[(Data.Artist2!=\"Nan\") & (Data.Rank <= 1)].value_counts()[0:10]\n",
    "ArtistData = pd.DataFrame({\n",
    "    \"Rank\" : list(range(1,11)),\n",
    "    \"MostWeeksWithSongsAtTopCharts\" : [str(i)+\" : \"+str(j) for j, i in zip(ArtistTop1.tolist(),pd.DataFrame(ArtistTop1).index.tolist())],\n",
    "    \"MostWeeksWithSongsInTop3Charts\" : [str(i)+\" : \"+str(j) for j, i in zip(ArtistTop3.tolist(),pd.DataFrame(ArtistTop3).index.tolist())],\n",
    "    \"MostWeeksWithSongsInTop10Charts\" : [str(i)+\" : \"+str(j) for j, i in zip(ArtistTop10.tolist(),pd.DataFrame(ArtistTop10).index.tolist())],\n",
    "    \"MostWeeksWithSongsInTop100Charts\" : [str(i)+\" : \"+str(j) for j, i in zip(ArtistAll.tolist(),pd.DataFrame(ArtistAll).index.tolist())]\n",
    "})\n",
    "ArtistData.to_csv(\"Leaderboards/ArtistLeaderboards.csv\")\n",
    "ArtistData.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Songs Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-07-01T10:09:54.686Z"
    }
   },
   "outputs": [],
   "source": [
    "SongsAll = Data.TrackArtist[Data.TrackArtist!=\"Nan\"].value_counts()[0:10]\n",
    "SongsTop10 = Data.TrackArtist[(Data.TrackArtist!=\"Nan\") & (Data.Rank <= 10)].value_counts()[0:10]\n",
    "SongsTop3 = Data.TrackArtist[(Data.TrackArtist!=\"Nan\") & (Data.Rank <= 3)].value_counts()[0:10]\n",
    "SongsTop1 = Data.TrackArtist[(Data.TrackArtist!=\"Nan\") & (Data.Rank <= 1)].value_counts()[0:10]\n",
    "SongsData = pd.DataFrame({\n",
    "    \"Rank\" : list(range(1,11)),\n",
    "    \"MostWeeksAtTopCharts\" : [str(i)+\" : \"+str(j) for j, i in zip(SongsTop1.tolist(),pd.DataFrame(SongsTop1).index.tolist())],\n",
    "    \"MostWeeksInTop3Charts\" : [str(i)+\" : \"+str(j) for j, i in zip(SongsTop3.tolist(),pd.DataFrame(SongsTop3).index.tolist())],\n",
    "    \"MostWeeksInTop10Charts\" : [str(i)+\" : \"+str(j) for j, i in zip(SongsTop10.tolist(),pd.DataFrame(SongsTop10).index.tolist())],\n",
    "    \"MostWeeksInTop100Charts\" : [str(i)+\" : \"+str(j) for j, i in zip(SongsAll.tolist(),pd.DataFrame(SongsAll).index.tolist())]\n",
    "})\n",
    "SongsData.to_csv(\"Leaderboards/SongLeaderboards.csv\")\n",
    "SongsData.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Genre Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-07-01T10:09:54.689Z"
    }
   },
   "outputs": [],
   "source": [
    "GenreData = pd.DataFrame({\"Date\" : Data.Date.unique()})\n",
    "GenreData[\"Blues\"] = [Data[(Data.Date == i) & (Data.Genre2==\"Blues\")].shape[0] for i in GenreData.Date]\n",
    "GenreData[\"Rock\"] = [Data[(Data.Date == i) & (Data.Genre2==\"Rock\")].shape[0] for i in GenreData.Date]\n",
    "GenreData[\"Pop\"] = [Data[(Data.Date == i) & (Data.Genre2==\"Pop\")].shape[0] for i in GenreData.Date]\n",
    "GenreData[\"HipHop\"] = [Data[(Data.Date == i) & (Data.Genre2==\"HipHop\")].shape[0] for i in GenreData.Date]\n",
    "GenreData[\"R&B\"] = [Data[(Data.Date == i) & (Data.Genre2==\"R&B\")].shape[0] for i in GenreData.Date]\n",
    "GenreData[\"Country\"] = [Data[(Data.Date == i) & (Data.Genre2==\"Country\")].shape[0] for i in GenreData.Date]\n",
    "GenreData[\"Folk\"] = [Data[(Data.Date == i) & (Data.Genre2==\"Folk\")].shape[0] for i in GenreData.Date]\n",
    "GenreData[\"Reggae\"] = [Data[(Data.Date == i) & (Data.Genre2==\"Reggae\")].shape[0] for i in GenreData.Date]\n",
    "GenreData[\"Electro\"] = [Data[(Data.Date == i) & (Data.Genre2==\"Electro\")].shape[0] for i in GenreData.Date]\n",
    "GenreData[\"Religous\"] = [Data[(Data.Date == i) & (Data.Genre2==\"Religous\")].shape[0] for i in GenreData.Date]\n",
    "GenreData.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Genre Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-07-01T10:09:54.692Z"
    }
   },
   "outputs": [],
   "source": [
    "GenreData.to_csv(\"GenreData.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Unique Song Dataset For Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-02T08:29:58.305788Z",
     "start_time": "2019-07-02T08:19:02.170466Z"
    }
   },
   "outputs": [],
   "source": [
    "UniqueData = Data[[\"TrackArtist\",\"Artist2\",\"Genre1\",\"Genre2\",\"LyricsClean\"]].drop_duplicates()\n",
    "UniqueData = UniqueData[UniqueData.TrackArtist.isna() == False]\n",
    "UniqueData[\"MaxRank\"] = [max(Data.Rank[Data.TrackArtist == i]) for i in UniqueData.TrackArtist]\n",
    "UniqueData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-02T08:29:59.942011Z",
     "start_time": "2019-07-02T08:29:58.394943Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.hist(UniqueData.MaxRank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-02T08:30:05.126289Z",
     "start_time": "2019-07-02T08:29:59.943668Z"
    },
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in UniqueData.Genre2.unique():\n",
    "    if pd.notna(i):\n",
    "        fig, axs = plt.subplots(ncols=1, figsize=(15,5))\n",
    "        sns.distplot(UniqueData.MaxRank[UniqueData.Genre2 == i], ax = axs).set_title(\"Highest Rank Achieved - {}\".format(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Training, Test, X & Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 3\n",
    "if x >2:\n",
    "    print(\"x greater than 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-02T08:30:05.138970Z",
     "start_time": "2019-07-02T08:30:05.127986Z"
    }
   },
   "outputs": [],
   "source": [
    "UniqueData = UniqueData.dropna(subset = [\"LyricsClean\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-02T08:30:05.877030Z",
     "start_time": "2019-07-02T08:30:05.141548Z"
    }
   },
   "outputs": [],
   "source": [
    "UniqueData.to_csv(\"temp.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-02T08:30:06.152003Z",
     "start_time": "2019-07-02T08:30:05.879266Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TrackArtist</th>\n",
       "      <th>Artist2</th>\n",
       "      <th>Genre1</th>\n",
       "      <th>Genre2</th>\n",
       "      <th>LyricsClean</th>\n",
       "      <th>MaxRank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Poor Little Fool By Ricky Nelson</td>\n",
       "      <td>Ricky Nelson</td>\n",
       "      <td>Pop/Rock</td>\n",
       "      <td>Rock</td>\n",
       "      <td>I used to play around with hearts that hastene...</td>\n",
       "      <td>71.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Patricia By Perez Prado And His Orchestra</td>\n",
       "      <td>Perez Prado</td>\n",
       "      <td>Latin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Instrumental</td>\n",
       "      <td>85.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Splish Splash By  Bobby Darin</td>\n",
       "      <td>Bobby Darin</td>\n",
       "      <td>Pop/Rock</td>\n",
       "      <td>Blues</td>\n",
       "      <td>splish splash I was taking a bath long about a...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hard Headed Woman By Elvis Presley With The Jo...</td>\n",
       "      <td>Elvis Presley</td>\n",
       "      <td>Pop/Rock</td>\n",
       "      <td>Rock</td>\n",
       "      <td>Well a hard headed woman, A soft hearted man B...</td>\n",
       "      <td>94.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rebel-'rouser By Duane Eddy His Twangy Guitar ...</td>\n",
       "      <td>Duane Eddy</td>\n",
       "      <td>Pop/Rock</td>\n",
       "      <td>Rock</td>\n",
       "      <td>Instrumental</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         TrackArtist         Artist2  \\\n",
       "0                   Poor Little Fool By Ricky Nelson    Ricky Nelson   \n",
       "1          Patricia By Perez Prado And His Orchestra     Perez Prado   \n",
       "2                      Splish Splash By  Bobby Darin     Bobby Darin   \n",
       "3  Hard Headed Woman By Elvis Presley With The Jo...  Elvis Presley    \n",
       "4  Rebel-'rouser By Duane Eddy His Twangy Guitar ...     Duane Eddy    \n",
       "\n",
       "     Genre1 Genre2                                        LyricsClean  MaxRank  \n",
       "0  Pop/Rock   Rock  I used to play around with hearts that hastene...     71.0  \n",
       "1     Latin    NaN                                       Instrumental     85.0  \n",
       "2  Pop/Rock  Blues  splish splash I was taking a bath long about a...      3.0  \n",
       "3  Pop/Rock   Rock  Well a hard headed woman, A soft hearted man B...     94.0  \n",
       "4  Pop/Rock   Rock                                       Instrumental     52.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UniqueData = pd.read_csv(\"temp.csv\").drop(columns = \"Unnamed: 0\")\n",
    "UniqueData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-02T08:30:06.880275Z",
     "start_time": "2019-07-02T08:30:06.153640Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numebr Of Nas For Genre1 343\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pop/Rock         10844\n",
       "R&B               5073\n",
       "Country           2184\n",
       "Rap               1918\n",
       "Vocal              829\n",
       "Electronic         494\n",
       "Jazz               227\n",
       "Latin              198\n",
       "Blues              180\n",
       "Folk               171\n",
       "Easy               144\n",
       "Reggae             129\n",
       "Stage               75\n",
       "Religious           61\n",
       "Comedy/Spoken       39\n",
       "International       27\n",
       "Children            18\n",
       "Classical           12\n",
       "New                  8\n",
       "Avant                4\n",
       "Holiday              1\n",
       "Name: Genre1, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Numebr Of Nas For Genre1\",len(UniqueData.Genre1)-UniqueData.Genre1.count())\n",
    "UniqueData.Genre1.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-02T08:30:06.895710Z",
     "start_time": "2019-07-02T08:30:06.881929Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numebr Of Nas For Genre2 4039\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Rock        5239\n",
       "Pop         4090\n",
       "R&B         3011\n",
       "Country     2221\n",
       "HipHop      1871\n",
       "Blues       1678\n",
       "Folk         339\n",
       "Electro      249\n",
       "Reggae       168\n",
       "Religous      74\n",
       "Name: Genre2, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Numebr Of Nas For Genre2\",len(UniqueData.Genre2)-UniqueData.Genre2.count())\n",
    "UniqueData.Genre2.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-02T08:30:07.048679Z",
     "start_time": "2019-07-02T08:30:06.897209Z"
    }
   },
   "outputs": [],
   "source": [
    "UniqueData = UniqueData.dropna(subset=[\"Genre1\"])\n",
    "UniqueData = UniqueData[UniqueData.Genre1.isin([\"Pop/Rock\"\n",
    "                                               ,\"R&B\"       \n",
    "                                               ,\"Country\"   \n",
    "                                               ,\"Rap\"       \n",
    "                                               ,\"Vocal\"     \n",
    "                                               ,\"Electronic\"\n",
    "                                               ,\"Jazz\"      \n",
    "                                               ,\"Latin\"     \n",
    "                                               ,\"Blues\"     \n",
    "                                               ,\"Folk\"      \n",
    "                                               ,\"Easy\"      \n",
    "                                               ,\"Reggae\"])]\n",
    "UniqueData.loc[UniqueData.Genre1==\"Jazz\"] = \"Blues\"\n",
    "UniqueData.loc[UniqueData.Genre1==\"Vocal\"] = \"Folk\"\n",
    "XTrain, XTest, YTrain, YTest = train_test_split(UniqueData[\"LyricsClean\"], UniqueData['Genre1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag Of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-02T08:30:14.904408Z",
     "start_time": "2019-07-02T08:30:07.050194Z"
    }
   },
   "outputs": [],
   "source": [
    "Vectorizer = TfidfVectorizer()\n",
    "Vectorizer.fit(XTrain)\n",
    "XTrain = Vectorizer.transform(XTrain)\n",
    "XTest  = Vectorizer.transform(XTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-02T08:30:18.408328Z",
     "start_time": "2019-07-02T08:30:14.906150Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1300: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn', n_jobs=-1,\n",
       "          penalty='l2', random_state=None, solver='warn', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Classifier = LogisticRegression(n_jobs=-1)\n",
    "Classifier.fit(XTrain, YTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-02T08:30:18.415251Z",
     "start_time": "2019-07-02T08:30:18.409967Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Pop/Rock', 'Latin', 'R&B', 'Country', 'Blues', 'Folk', 'Easy',\n",
       "       'Reggae', 'Electronic', 'Rap'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UniqueData.Genre1.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-02T08:30:18.560935Z",
     "start_time": "2019-07-02T08:30:18.417299Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6812957780027392\n",
      "0.631654162200786\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  61,    2,    0,    0,    0,    0,   27,    9,    1,    0],\n",
       "       [   0,   48,    0,    0,    0,    0,  440,   58,    2,    0],\n",
       "       [   0,    1,    0,    0,    0,    0,   30,    4,    0,    0],\n",
       "       [   0,    3,    0,    0,    0,    0,   99,   20,    5,    0],\n",
       "       [   0,    0,    0,    0,  206,    0,   34,    8,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    4,   29,    8,    1,    0],\n",
       "       [   0,   11,    0,    0,    1,    1, 2498,  154,    6,    0],\n",
       "       [   0,    5,    0,    0,    0,    1,  789,  456,   35,    0],\n",
       "       [   0,    0,    0,    0,    0,    1,  198,   39,  262,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,   31,    4,    5,    1]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f1_score(YTrain,Classifier.predict(XTrain), average=\"micro\"))\n",
    "print(f1_score(YTest,Classifier.predict(XTest), average=\"micro\"))\n",
    "confusion_matrix(YTest,Classifier.predict(XTest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Deep Learning Model - Sequential Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-02T08:30:18.572012Z",
     "start_time": "2019-07-02T08:30:18.562849Z"
    }
   },
   "outputs": [],
   "source": [
    "Encoder = LabelEncoder()\n",
    "Encoder.fit(YTrain)\n",
    "YTrainNum = Encoder.transform(YTrain)\n",
    "YTrainDummy = np_utils.to_categorical(YTrainNum)\n",
    "YTestNum = Encoder.transform(YTest)\n",
    "YTestDummy = np_utils.to_categorical(YTestNum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-02T08:30:18.892443Z",
     "start_time": "2019-07-02T08:30:18.573670Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 30)                1157100   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 30)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 20)                620       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                210       \n",
      "=================================================================\n",
      "Total params: 1,157,930\n",
      "Trainable params: 1,157,930\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "InputDim = XTrain.shape[1]\n",
    "Model = Sequential()\n",
    "Model.add(layers.Dense(30, input_dim=InputDim, activation='relu'))\n",
    "Model.add(layers.Dropout(rate = 0.4))\n",
    "Model.add(layers.Dense(20, activation='relu'))\n",
    "Model.add(layers.Dropout(rate = 0.4))\n",
    "Model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "Model.compile(loss='categorical_crossentropy', \n",
    "              optimizer=\"adam\",\n",
    "              metrics=[\"acc\"])\n",
    "Model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-02T08:36:38.413862Z",
     "start_time": "2019-07-02T08:30:18.894216Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 16793 samples, validate on 5598 samples\n",
      "Epoch 1/25\n",
      "16793/16793 [==============================] - 9s 559us/step - loss: 1.4883 - acc: 0.5073 - val_loss: 1.2450 - val_acc: 0.5688\n",
      "Epoch 2/25\n",
      "16793/16793 [==============================] - 8s 449us/step - loss: 1.2006 - acc: 0.5779 - val_loss: 1.1316 - val_acc: 0.6008\n",
      "Epoch 3/25\n",
      "16793/16793 [==============================] - 8s 448us/step - loss: 1.0629 - acc: 0.6237 - val_loss: 1.0803 - val_acc: 0.6440\n",
      "Epoch 4/25\n",
      "16793/16793 [==============================] - 8s 449us/step - loss: 0.9453 - acc: 0.6750 - val_loss: 1.0656 - val_acc: 0.6672\n",
      "Epoch 5/25\n",
      "16793/16793 [==============================] - 8s 448us/step - loss: 0.8369 - acc: 0.7172 - val_loss: 1.0787 - val_acc: 0.6777\n",
      "Epoch 6/25\n",
      "16793/16793 [==============================] - 8s 447us/step - loss: 0.7655 - acc: 0.7426 - val_loss: 1.1071 - val_acc: 0.6793\n",
      "Epoch 7/25\n",
      "16793/16793 [==============================] - 8s 447us/step - loss: 0.7161 - acc: 0.7606 - val_loss: 1.1437 - val_acc: 0.6813\n",
      "Epoch 8/25\n",
      "16793/16793 [==============================] - 8s 447us/step - loss: 0.6729 - acc: 0.7734 - val_loss: 1.1688 - val_acc: 0.6836\n",
      "Epoch 9/25\n",
      "16793/16793 [==============================] - 8s 448us/step - loss: 0.6376 - acc: 0.7847 - val_loss: 1.2253 - val_acc: 0.6788\n",
      "Epoch 10/25\n",
      "16793/16793 [==============================] - 8s 447us/step - loss: 0.6098 - acc: 0.7935 - val_loss: 1.2436 - val_acc: 0.6847\n",
      "Epoch 11/25\n",
      "16793/16793 [==============================] - 8s 448us/step - loss: 0.5864 - acc: 0.8062 - val_loss: 1.2937 - val_acc: 0.6888\n",
      "Epoch 12/25\n",
      "16793/16793 [==============================] - 8s 449us/step - loss: 0.5628 - acc: 0.8109 - val_loss: 1.3178 - val_acc: 0.6881\n",
      "Epoch 13/25\n",
      "16793/16793 [==============================] - 8s 469us/step - loss: 0.5445 - acc: 0.8136 - val_loss: 1.3772 - val_acc: 0.6965\n",
      "Epoch 14/25\n",
      "16793/16793 [==============================] - 8s 450us/step - loss: 0.5256 - acc: 0.8169 - val_loss: 1.4032 - val_acc: 0.6938\n",
      "Epoch 15/25\n",
      "16793/16793 [==============================] - 8s 448us/step - loss: 0.5230 - acc: 0.8228 - val_loss: 1.4028 - val_acc: 0.6976\n",
      "Epoch 16/25\n",
      "16793/16793 [==============================] - 8s 448us/step - loss: 0.4959 - acc: 0.8283 - val_loss: 1.4855 - val_acc: 0.6949\n",
      "Epoch 17/25\n",
      "16793/16793 [==============================] - 8s 448us/step - loss: 0.4980 - acc: 0.8267 - val_loss: 1.4872 - val_acc: 0.6988\n",
      "Epoch 18/25\n",
      "16793/16793 [==============================] - 8s 447us/step - loss: 0.4869 - acc: 0.8274 - val_loss: 1.5414 - val_acc: 0.6963\n",
      "Epoch 19/25\n",
      "16793/16793 [==============================] - 8s 447us/step - loss: 0.4802 - acc: 0.8348 - val_loss: 1.5775 - val_acc: 0.6951\n",
      "Epoch 20/25\n",
      "16793/16793 [==============================] - 7s 446us/step - loss: 0.4626 - acc: 0.8371 - val_loss: 1.6485 - val_acc: 0.6935\n",
      "Epoch 21/25\n",
      "16793/16793 [==============================] - 7s 447us/step - loss: 0.4627 - acc: 0.8398 - val_loss: 1.6176 - val_acc: 0.6908\n",
      "Epoch 22/25\n",
      "16793/16793 [==============================] - 7s 445us/step - loss: 0.4569 - acc: 0.8392 - val_loss: 1.6632 - val_acc: 0.6995\n",
      "Epoch 23/25\n",
      "16793/16793 [==============================] - 7s 446us/step - loss: 0.4540 - acc: 0.8428 - val_loss: 1.6783 - val_acc: 0.6961\n",
      "Epoch 24/25\n",
      "16793/16793 [==============================] - 7s 446us/step - loss: 0.4430 - acc: 0.8437 - val_loss: 1.7134 - val_acc: 0.6927\n",
      "Epoch 25/25\n",
      "16793/16793 [==============================] - 7s 446us/step - loss: 0.4357 - acc: 0.8448 - val_loss: 1.7306 - val_acc: 0.6947\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fbe6c39da20>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Model.fit(XTrain, YTrainDummy,\n",
    "          epochs=25,\n",
    "          validation_data=(XTest, YTestDummy),\n",
    "          batch_size=15,\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-02T08:36:41.745968Z",
     "start_time": "2019-07-02T08:36:38.415530Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9021616149586137\n",
      "0.6947123972847445\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  69,    1,    0,    1,    0,    0,   17,   12,    0,    0],\n",
       "       [   0,  253,    0,    7,    0,    0,  198,   85,    5,    0],\n",
       "       [   0,    0,    0,   10,    0,    0,   20,    4,    1,    0],\n",
       "       [   0,    4,    0,   46,    0,    0,   48,   26,    3,    0],\n",
       "       [   0,    2,    0,    2,  212,    0,   25,    6,    1,    0],\n",
       "       [   0,    7,    0,    8,    0,    4,   16,    6,    1,    0],\n",
       "       [   6,  106,    0,   20,    4,    0, 2132,  367,   36,    0],\n",
       "       [   0,   38,    0,   21,    1,    1,  350,  833,   42,    0],\n",
       "       [   1,    5,    0,    5,    0,    0,   74,   75,  340,    0],\n",
       "       [   0,    5,    0,   16,    0,    1,   10,    6,    3,    0]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f1_score(YTrainNum,Model.predict_classes(XTrain), average=\"micro\"))\n",
    "print(f1_score(YTestNum,Model.predict_classes(XTest), average=\"micro\"))\n",
    "confusion_matrix(YTestNum,Model.predict_classes(XTest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embedding Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-02T08:36:41.756279Z",
     "start_time": "2019-07-02T08:36:41.747591Z"
    }
   },
   "outputs": [],
   "source": [
    "XTrain, XTest, YTrain, YTest = train_test_split(UniqueData[\"LyricsClean\"], UniqueData['Genre1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-02T08:36:41.768065Z",
     "start_time": "2019-07-02T08:36:41.757629Z"
    }
   },
   "outputs": [],
   "source": [
    "Encoder = LabelEncoder()\n",
    "Encoder.fit(YTrain)\n",
    "YTrainNum = Encoder.transform(YTrain)\n",
    "YTrainDummy = np_utils.to_categorical(YTrainNum)\n",
    "YTestNum = Encoder.transform(YTest)\n",
    "YTestDummy = np_utils.to_categorical(YTestNum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-02T08:36:47.292084Z",
     "start_time": "2019-07-02T08:36:41.771746Z"
    }
   },
   "outputs": [],
   "source": [
    "TokenModel = Tokenizer(num_words=5000)\n",
    "TokenModel.fit_on_texts(XTrain.tolist())\n",
    "XTrain = TokenModel.texts_to_sequences(XTrain.tolist())\n",
    "#XTrain = TokenModel.texts_to_matrix(XTrain, mode='tfidf')\n",
    "XTest = TokenModel.texts_to_sequences(XTest.tolist())\n",
    "#XTest = TokenModel.texts_to_matrix(XTest, mode='tfidf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-02T08:36:47.810871Z",
     "start_time": "2019-07-02T08:36:47.295302Z"
    }
   },
   "outputs": [],
   "source": [
    "XTrain = pad_sequences(XTrain, padding='post', maxlen=500)\n",
    "XTest = pad_sequences(XTest, padding='post', maxlen=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-02T08:36:47.892212Z",
     "start_time": "2019-07-02T08:36:47.812619Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 500, 200)          1000000   \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 50)                10050     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                510       \n",
      "=================================================================\n",
      "Total params: 1,010,560\n",
      "Trainable params: 1,010,560\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "InputDim = XTrain.shape[1]\n",
    "Model = Sequential()\n",
    "Model.add(layers.Embedding(input_dim=5000,\n",
    "                           output_dim=200,\n",
    "                           input_length=500))\n",
    "Model.add(layers.GlobalMaxPooling1D())\n",
    "#Model.add(layers.Flatten())\n",
    "Model.add(layers.Dense(50, activation='relu'))\n",
    "#Model.add(layers.SpatialDropout1D(0.2))\n",
    "#Model.add(layers.GRU(units=32, dropout=0.2, recurrent_dropout=0.2))\n",
    "#Model.add(layers.LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "#Model.add(layers.Dense(40, activation='relu'))\n",
    "#Model.add(layers.Dropout(rate = 0.3))\n",
    "Model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "Model.compile(loss='categorical_crossentropy', \n",
    "              optimizer=\"adam\",\n",
    "              metrics=[\"acc\"])\n",
    "Model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-02T08:43:05.795368Z",
     "start_time": "2019-07-02T08:36:47.893809Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Train on 16793 samples, validate on 5598 samples\n",
      "Epoch 1/25\n",
      "16793/16793 [==============================] - 6s 359us/step - loss: 1.2840 - acc: 0.5635 - val_loss: 1.1574 - val_acc: 0.5990\n",
      "Epoch 2/25\n",
      "16793/16793 [==============================] - 6s 332us/step - loss: 1.0848 - acc: 0.6388 - val_loss: 1.0808 - val_acc: 0.6377\n",
      "Epoch 3/25\n",
      "16793/16793 [==============================] - 6s 332us/step - loss: 0.9311 - acc: 0.6964 - val_loss: 1.0557 - val_acc: 0.6538\n",
      "Epoch 4/25\n",
      "16793/16793 [==============================] - 6s 332us/step - loss: 0.7916 - acc: 0.7474 - val_loss: 1.0462 - val_acc: 0.6738\n",
      "Epoch 5/25\n",
      "16793/16793 [==============================] - 6s 332us/step - loss: 0.6680 - acc: 0.7913 - val_loss: 1.0587 - val_acc: 0.6729\n",
      "Epoch 6/25\n",
      "16793/16793 [==============================] - 6s 332us/step - loss: 0.5744 - acc: 0.8163 - val_loss: 1.0763 - val_acc: 0.6897\n",
      "Epoch 7/25\n",
      "16793/16793 [==============================] - 6s 332us/step - loss: 0.4920 - acc: 0.8404 - val_loss: 1.1347 - val_acc: 0.6897\n",
      "Epoch 8/25\n",
      "16793/16793 [==============================] - 6s 332us/step - loss: 0.4307 - acc: 0.8602 - val_loss: 1.1325 - val_acc: 0.6958\n",
      "Epoch 9/25\n",
      "16793/16793 [==============================] - 6s 332us/step - loss: 0.3883 - acc: 0.8720 - val_loss: 1.1916 - val_acc: 0.6817\n",
      "Epoch 10/25\n",
      "16793/16793 [==============================] - 6s 332us/step - loss: 0.3568 - acc: 0.8829 - val_loss: 1.2077 - val_acc: 0.7015\n",
      "Epoch 11/25\n",
      "16793/16793 [==============================] - 6s 333us/step - loss: 0.3305 - acc: 0.8904 - val_loss: 1.2434 - val_acc: 0.6840\n",
      "Epoch 12/25\n",
      "16793/16793 [==============================] - 6s 333us/step - loss: 0.3121 - acc: 0.8942 - val_loss: 1.2553 - val_acc: 0.6947\n",
      "Epoch 13/25\n",
      "16793/16793 [==============================] - 6s 332us/step - loss: 0.3013 - acc: 0.8958 - val_loss: 1.2279 - val_acc: 0.7022\n",
      "Epoch 14/25\n",
      "16793/16793 [==============================] - 6s 340us/step - loss: 0.2864 - acc: 0.9002 - val_loss: 1.2534 - val_acc: 0.7040\n",
      "Epoch 15/25\n",
      "16793/16793 [==============================] - 6s 340us/step - loss: 0.2795 - acc: 0.9028 - val_loss: 1.2681 - val_acc: 0.7076\n",
      "Epoch 16/25\n",
      "16793/16793 [==============================] - 6s 332us/step - loss: 0.2726 - acc: 0.9015 - val_loss: 1.2681 - val_acc: 0.7045\n",
      "Epoch 17/25\n",
      "16793/16793 [==============================] - 6s 332us/step - loss: 0.2677 - acc: 0.9025 - val_loss: 1.2484 - val_acc: 0.6827\n",
      "Epoch 18/25\n",
      "16793/16793 [==============================] - 6s 332us/step - loss: 0.2617 - acc: 0.9037 - val_loss: 1.2446 - val_acc: 0.7095\n",
      "Epoch 19/25\n",
      "16793/16793 [==============================] - 6s 332us/step - loss: 0.2537 - acc: 0.9070 - val_loss: 1.2429 - val_acc: 0.7035\n",
      "Epoch 20/25\n",
      "16793/16793 [==============================] - 6s 332us/step - loss: 0.2520 - acc: 0.9034 - val_loss: 1.2334 - val_acc: 0.6970\n",
      "Epoch 21/25\n",
      "16793/16793 [==============================] - 6s 332us/step - loss: 0.2472 - acc: 0.9045 - val_loss: 1.2865 - val_acc: 0.7126\n",
      "Epoch 22/25\n",
      "16793/16793 [==============================] - 6s 332us/step - loss: 0.2422 - acc: 0.9055 - val_loss: 1.2654 - val_acc: 0.7081\n",
      "Epoch 23/25\n",
      "16793/16793 [==============================] - 6s 333us/step - loss: 0.2390 - acc: 0.9054 - val_loss: 1.2952 - val_acc: 0.7006\n",
      "Epoch 24/25\n",
      "16793/16793 [==============================] - 6s 332us/step - loss: 0.2341 - acc: 0.9067 - val_loss: 1.2670 - val_acc: 0.6969\n",
      "Epoch 25/25\n",
      "16793/16793 [==============================] - 6s 331us/step - loss: 0.2304 - acc: 0.9079 - val_loss: 1.3171 - val_acc: 0.7031\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fbe1c6ad2b0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Model.fit(XTrain, \n",
    "          YTrainDummy,\n",
    "          epochs=25,\n",
    "          validation_data=(XTest, YTestDummy),\n",
    "          batch_size=15,\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-02T08:43:07.223569Z",
     "start_time": "2019-07-02T08:43:05.796918Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9241350562734473\n",
      "0.7031082529474812\n",
      "😊\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  67,    2,    0,    0,    1,    0,   21,    9,    0,    2],\n",
       "       [   0,  238,    2,    3,    3,    2,  184,   81,    9,    2],\n",
       "       [   0,    1,    6,    0,    1,    0,   16,    8,    0,    0],\n",
       "       [   0,    7,    0,   41,    0,    1,   61,   26,    5,    0],\n",
       "       [   0,    5,    0,    0,  229,    0,   15,    9,    0,    0],\n",
       "       [   0,    1,    0,    0,    0,   25,    9,   11,    0,    0],\n",
       "       [   2,  105,    1,    3,    8,   14, 2090,  399,   42,    7],\n",
       "       [   1,   56,    3,    7,    4,    6,  332,  897,   24,    2],\n",
       "       [   1,    2,    0,    3,    0,    0,   80,   53,  324,    1],\n",
       "       [   0,    0,    0,    0,    0,    0,    5,    2,    2,   19]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f1_score(YTrainNum,Model.predict_classes(XTrain), average=\"micro\"))\n",
    "print(f1_score(YTestNum,Model.predict_classes(XTest), average=\"micro\"))\n",
    "print(\"😊\")\n",
    "confusion_matrix(YTestNum,Model.predict_classes(XTest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LTSTM Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-02T08:58:53.638929Z",
     "start_time": "2019-07-02T08:58:53.630669Z"
    }
   },
   "outputs": [],
   "source": [
    "XTrain, XTest, YTrain, YTest = train_test_split(UniqueData[\"LyricsClean\"], UniqueData['Genre1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-02T08:58:55.005758Z",
     "start_time": "2019-07-02T08:58:54.997329Z"
    }
   },
   "outputs": [],
   "source": [
    "Encoder = LabelEncoder()\n",
    "Encoder.fit(YTrain)\n",
    "YTrainNum = Encoder.transform(YTrain)\n",
    "YTrainDummy = np_utils.to_categorical(YTrainNum)\n",
    "YTestNum = Encoder.transform(YTest)\n",
    "YTestDummy = np_utils.to_categorical(YTestNum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-02T08:59:02.916848Z",
     "start_time": "2019-07-02T08:58:57.485527Z"
    }
   },
   "outputs": [],
   "source": [
    "TokenModel = Tokenizer(num_words=5000)\n",
    "TokenModel.fit_on_texts(XTrain.tolist())\n",
    "XTrain = TokenModel.texts_to_sequences(XTrain.tolist())\n",
    "#XTrain = TokenModel.texts_to_matrix(XTrain, mode='tfidf')\n",
    "XTest = TokenModel.texts_to_sequences(XTest.tolist())\n",
    "#XTest = TokenModel.texts_to_matrix(XTest, mode='tfidf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-02T08:59:13.599162Z",
     "start_time": "2019-07-02T08:59:13.081223Z"
    }
   },
   "outputs": [],
   "source": [
    "XTrain = pad_sequences(XTrain, padding='post', maxlen=500)\n",
    "XTest = pad_sequences(XTest, padding='post', maxlen=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-02T11:16:37.531129Z",
     "start_time": "2019-07-02T11:16:37.147569Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 500, 100)          500000    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_4 (Spatial (None, 500, 100)          0         \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_4 (CuDNNLSTM)     (None, 100)               80800     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 581,810\n",
      "Trainable params: 581,810\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "InputDim = XTrain.shape[1]\n",
    "Model = Sequential()\n",
    "Model.add(layers.Embedding(input_dim=5000,\n",
    "                           output_dim=100,\n",
    "                           input_length=500))\n",
    "#Model.add(layers.GlobalMaxPooling1D())\n",
    "#Model.add(layers.Flatten())\n",
    "#Model.add(layers.Dense(50, activation='relu'))\n",
    "Model.add(layers.SpatialDropout1D(0.2))\n",
    "#Model.add(layers.GRU(units=32, dropout=0.2, recurrent_dropout=0.2))\n",
    "Model.add(layers.CuDNNLSTM(100))\n",
    "#Model.add(layers.Dense(40, activation='relu'))\n",
    "Model.add(layers.Dropout(rate = 0.3))\n",
    "Model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "Model.compile(loss='categorical_crossentropy', \n",
    "              optimizer=\"adam\",\n",
    "              metrics=[\"acc\"])\n",
    "Model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-02T11:30:15.542251Z",
     "start_time": "2019-07-02T11:16:41.163396Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16793 samples, validate on 5598 samples\n",
      "Epoch 1/100\n",
      "16793/16793 [==============================] - 9s 550us/step - loss: 1.5762 - acc: 0.4842 - val_loss: 1.4442 - val_acc: 0.5211\n",
      "Epoch 2/100\n",
      "16793/16793 [==============================] - 8s 478us/step - loss: 1.4713 - acc: 0.5111 - val_loss: 1.4249 - val_acc: 0.5263\n",
      "Epoch 3/100\n",
      "16793/16793 [==============================] - 8s 480us/step - loss: 1.4567 - acc: 0.5165 - val_loss: 1.4189 - val_acc: 0.5280\n",
      "Epoch 4/100\n",
      "16793/16793 [==============================] - 8s 480us/step - loss: 1.4467 - acc: 0.5180 - val_loss: 1.4307 - val_acc: 0.5266\n",
      "Epoch 5/100\n",
      "16793/16793 [==============================] - 8s 478us/step - loss: 1.4352 - acc: 0.5209 - val_loss: 1.4074 - val_acc: 0.5304\n",
      "Epoch 6/100\n",
      "16793/16793 [==============================] - 8s 480us/step - loss: 1.4244 - acc: 0.5216 - val_loss: 1.3990 - val_acc: 0.5302\n",
      "Epoch 7/100\n",
      "16793/16793 [==============================] - 8s 481us/step - loss: 1.4039 - acc: 0.5243 - val_loss: 1.3398 - val_acc: 0.5279\n",
      "Epoch 8/100\n",
      "16793/16793 [==============================] - 8s 478us/step - loss: 1.3065 - acc: 0.5511 - val_loss: 1.2947 - val_acc: 0.5634\n",
      "Epoch 9/100\n",
      "16793/16793 [==============================] - 8s 479us/step - loss: 1.2952 - acc: 0.5511 - val_loss: 1.2995 - val_acc: 0.5438\n",
      "Epoch 10/100\n",
      "16793/16793 [==============================] - 8s 480us/step - loss: 1.3169 - acc: 0.5425 - val_loss: 1.3159 - val_acc: 0.5479\n",
      "Epoch 11/100\n",
      "16793/16793 [==============================] - 8s 478us/step - loss: 1.3044 - acc: 0.5534 - val_loss: 1.2694 - val_acc: 0.5595\n",
      "Epoch 12/100\n",
      "16793/16793 [==============================] - 8s 479us/step - loss: 1.2870 - acc: 0.5619 - val_loss: 1.3558 - val_acc: 0.5489\n",
      "Epoch 13/100\n",
      "16793/16793 [==============================] - 8s 480us/step - loss: 1.3273 - acc: 0.5637 - val_loss: 1.3508 - val_acc: 0.5279\n",
      "Epoch 14/100\n",
      "16793/16793 [==============================] - 8s 478us/step - loss: 1.2998 - acc: 0.5784 - val_loss: 1.2677 - val_acc: 0.5168\n",
      "Epoch 15/100\n",
      "16793/16793 [==============================] - 8s 480us/step - loss: 1.1980 - acc: 0.6104 - val_loss: 1.2343 - val_acc: 0.5761\n",
      "Epoch 16/100\n",
      "16793/16793 [==============================] - 8s 480us/step - loss: 1.1787 - acc: 0.6225 - val_loss: 1.3041 - val_acc: 0.5613\n",
      "Epoch 17/100\n",
      "16793/16793 [==============================] - 8s 478us/step - loss: 1.2414 - acc: 0.6029 - val_loss: 1.2271 - val_acc: 0.5895\n",
      "Epoch 18/100\n",
      "16793/16793 [==============================] - 8s 479us/step - loss: 1.1425 - acc: 0.6430 - val_loss: 1.2243 - val_acc: 0.5909\n",
      "Epoch 19/100\n",
      "16793/16793 [==============================] - 8s 481us/step - loss: 1.1218 - acc: 0.6566 - val_loss: 1.2111 - val_acc: 0.6033\n",
      "Epoch 20/100\n",
      "16793/16793 [==============================] - 8s 478us/step - loss: 1.1011 - acc: 0.6682 - val_loss: 1.1996 - val_acc: 0.6147\n",
      "Epoch 21/100\n",
      "16793/16793 [==============================] - 8s 480us/step - loss: 1.0989 - acc: 0.6728 - val_loss: 1.2099 - val_acc: 0.6063\n",
      "Epoch 22/100\n",
      "16793/16793 [==============================] - 8s 480us/step - loss: 1.1963 - acc: 0.6496 - val_loss: 1.3322 - val_acc: 0.5813\n",
      "Epoch 23/100\n",
      "16793/16793 [==============================] - 8s 478us/step - loss: 1.2138 - acc: 0.6451 - val_loss: 1.3616 - val_acc: 0.5729\n",
      "Epoch 24/100\n",
      "16793/16793 [==============================] - 8s 479us/step - loss: 1.1547 - acc: 0.6624 - val_loss: 1.1917 - val_acc: 0.6186\n",
      "Epoch 25/100\n",
      "16793/16793 [==============================] - 8s 480us/step - loss: 1.0460 - acc: 0.6942 - val_loss: 1.1905 - val_acc: 0.6175\n",
      "Epoch 26/100\n",
      "16793/16793 [==============================] - 8s 479us/step - loss: 1.0287 - acc: 0.7042 - val_loss: 1.1884 - val_acc: 0.6275\n",
      "Epoch 27/100\n",
      "16793/16793 [==============================] - 8s 480us/step - loss: 1.0339 - acc: 0.7033 - val_loss: 1.2086 - val_acc: 0.6154\n",
      "Epoch 28/100\n",
      "16793/16793 [==============================] - 8s 481us/step - loss: 1.0489 - acc: 0.6953 - val_loss: 1.2158 - val_acc: 0.6166\n",
      "Epoch 29/100\n",
      "16793/16793 [==============================] - 8s 478us/step - loss: 1.0356 - acc: 0.7015 - val_loss: 1.2155 - val_acc: 0.6156\n",
      "Epoch 30/100\n",
      "16793/16793 [==============================] - 8s 479us/step - loss: 1.0347 - acc: 0.7023 - val_loss: 1.2169 - val_acc: 0.6200\n",
      "Epoch 31/100\n",
      "16793/16793 [==============================] - 8s 480us/step - loss: 1.0287 - acc: 0.7039 - val_loss: 1.2281 - val_acc: 0.6243\n",
      "Epoch 32/100\n",
      "16793/16793 [==============================] - 8s 478us/step - loss: 1.0289 - acc: 0.7043 - val_loss: 1.2178 - val_acc: 0.6209\n",
      "Epoch 33/100\n",
      "16793/16793 [==============================] - 8s 479us/step - loss: 1.0223 - acc: 0.7052 - val_loss: 1.2025 - val_acc: 0.6259\n",
      "Epoch 34/100\n",
      "16793/16793 [==============================] - 8s 480us/step - loss: 1.0227 - acc: 0.7062 - val_loss: 1.2544 - val_acc: 0.6131\n",
      "Epoch 35/100\n",
      "16793/16793 [==============================] - 8s 478us/step - loss: 1.0252 - acc: 0.7067 - val_loss: 1.2187 - val_acc: 0.6222\n",
      "Epoch 36/100\n",
      "16793/16793 [==============================] - 8s 480us/step - loss: 1.0311 - acc: 0.7051 - val_loss: 1.4210 - val_acc: 0.5843\n",
      "Epoch 37/100\n",
      "16793/16793 [==============================] - 8s 480us/step - loss: 1.1649 - acc: 0.6742 - val_loss: 1.3411 - val_acc: 0.5882\n",
      "Epoch 38/100\n",
      "16793/16793 [==============================] - 8s 478us/step - loss: 1.1461 - acc: 0.6765 - val_loss: 1.3460 - val_acc: 0.5886\n",
      "Epoch 39/100\n",
      "16793/16793 [==============================] - 8s 479us/step - loss: 1.1455 - acc: 0.6755 - val_loss: 1.3596 - val_acc: 0.5781\n",
      "Epoch 40/100\n",
      "16793/16793 [==============================] - 8s 480us/step - loss: 1.1341 - acc: 0.6788 - val_loss: 1.3549 - val_acc: 0.5815\n",
      "Epoch 41/100\n",
      "16793/16793 [==============================] - 8s 478us/step - loss: 1.1305 - acc: 0.6802 - val_loss: 1.3311 - val_acc: 0.5911\n",
      "Epoch 42/100\n",
      "16793/16793 [==============================] - 8s 480us/step - loss: 1.1273 - acc: 0.6814 - val_loss: 1.3459 - val_acc: 0.5906\n",
      "Epoch 43/100\n",
      "16793/16793 [==============================] - 8s 481us/step - loss: 1.0627 - acc: 0.6933 - val_loss: 1.1975 - val_acc: 0.6236\n",
      "Epoch 44/100\n",
      "16793/16793 [==============================] - 8s 478us/step - loss: 0.9952 - acc: 0.7172 - val_loss: 1.2025 - val_acc: 0.6243\n",
      "Epoch 45/100\n",
      "16793/16793 [==============================] - 8s 479us/step - loss: 0.9853 - acc: 0.7196 - val_loss: 1.2192 - val_acc: 0.6031\n",
      "Epoch 46/100\n",
      "16793/16793 [==============================] - 8s 480us/step - loss: 0.9873 - acc: 0.7188 - val_loss: 1.2197 - val_acc: 0.6217\n",
      "Epoch 47/100\n",
      "16793/16793 [==============================] - 8s 478us/step - loss: 0.9705 - acc: 0.7258 - val_loss: 1.1884 - val_acc: 0.6409\n",
      "Epoch 48/100\n",
      "16793/16793 [==============================] - 8s 480us/step - loss: 0.9586 - acc: 0.7308 - val_loss: 1.2023 - val_acc: 0.6383\n",
      "Epoch 49/100\n",
      "16793/16793 [==============================] - 8s 480us/step - loss: 0.9588 - acc: 0.7298 - val_loss: 1.1840 - val_acc: 0.6409\n",
      "Epoch 50/100\n",
      "16793/16793 [==============================] - 8s 478us/step - loss: 0.9479 - acc: 0.7329 - val_loss: 1.1940 - val_acc: 0.6372\n",
      "Epoch 51/100\n",
      "16793/16793 [==============================] - 8s 480us/step - loss: 0.9345 - acc: 0.7337 - val_loss: 1.1681 - val_acc: 0.6399\n",
      "Epoch 52/100\n",
      "16793/16793 [==============================] - 8s 481us/step - loss: 0.9212 - acc: 0.7359 - val_loss: 1.1695 - val_acc: 0.6409\n",
      "Epoch 53/100\n",
      "16793/16793 [==============================] - 8s 478us/step - loss: 0.9074 - acc: 0.7348 - val_loss: 1.1863 - val_acc: 0.6317\n",
      "Epoch 54/100\n",
      "16793/16793 [==============================] - 8s 479us/step - loss: 0.8889 - acc: 0.7383 - val_loss: 1.1885 - val_acc: 0.6386\n",
      "Epoch 55/100\n",
      "16793/16793 [==============================] - 8s 480us/step - loss: 0.9028 - acc: 0.7353 - val_loss: 1.2149 - val_acc: 0.6342\n",
      "Epoch 56/100\n",
      "16793/16793 [==============================] - 8s 478us/step - loss: 0.8856 - acc: 0.7412 - val_loss: 1.1639 - val_acc: 0.6372\n",
      "Epoch 57/100\n",
      "16793/16793 [==============================] - 8s 479us/step - loss: 0.8481 - acc: 0.7533 - val_loss: 1.1850 - val_acc: 0.6299\n",
      "Epoch 58/100\n",
      "16793/16793 [==============================] - 8s 480us/step - loss: 0.8185 - acc: 0.7610 - val_loss: 1.1954 - val_acc: 0.6365\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16793/16793 [==============================] - 8s 478us/step - loss: 0.7980 - acc: 0.7681 - val_loss: 1.2024 - val_acc: 0.6345\n",
      "Epoch 60/100\n",
      "16793/16793 [==============================] - 8s 479us/step - loss: 0.7834 - acc: 0.7740 - val_loss: 1.2075 - val_acc: 0.6195\n",
      "Epoch 61/100\n",
      "16793/16793 [==============================] - 8s 480us/step - loss: 0.7643 - acc: 0.7794 - val_loss: 1.2139 - val_acc: 0.6347\n",
      "Epoch 62/100\n",
      "16793/16793 [==============================] - 8s 478us/step - loss: 0.7531 - acc: 0.7821 - val_loss: 1.1917 - val_acc: 0.6363\n",
      "Epoch 63/100\n",
      "16793/16793 [==============================] - 8s 480us/step - loss: 0.7319 - acc: 0.7876 - val_loss: 1.2222 - val_acc: 0.6486\n",
      "Epoch 64/100\n",
      "16793/16793 [==============================] - 8s 480us/step - loss: 0.7223 - acc: 0.7910 - val_loss: 1.2564 - val_acc: 0.6467\n",
      "Epoch 65/100\n",
      "16793/16793 [==============================] - 8s 479us/step - loss: 0.7069 - acc: 0.7944 - val_loss: 1.2577 - val_acc: 0.6199\n",
      "Epoch 66/100\n",
      "16793/16793 [==============================] - 8s 479us/step - loss: 0.7143 - acc: 0.7881 - val_loss: 1.2820 - val_acc: 0.6458\n",
      "Epoch 67/100\n",
      "16793/16793 [==============================] - 8s 481us/step - loss: 0.6871 - acc: 0.7975 - val_loss: 1.2394 - val_acc: 0.6318\n",
      "Epoch 68/100\n",
      "16793/16793 [==============================] - 8s 479us/step - loss: 0.6817 - acc: 0.7984 - val_loss: 1.2170 - val_acc: 0.6429\n",
      "Epoch 69/100\n",
      "16793/16793 [==============================] - 8s 480us/step - loss: 0.6697 - acc: 0.8006 - val_loss: 1.2387 - val_acc: 0.6375\n",
      "Epoch 70/100\n",
      "16793/16793 [==============================] - 8s 480us/step - loss: 0.6667 - acc: 0.8028 - val_loss: 1.3308 - val_acc: 0.6327\n",
      "Epoch 71/100\n",
      "16793/16793 [==============================] - 8s 478us/step - loss: 0.6626 - acc: 0.8031 - val_loss: 1.2883 - val_acc: 0.6499\n",
      "Epoch 72/100\n",
      "16793/16793 [==============================] - 8s 480us/step - loss: 0.6519 - acc: 0.8061 - val_loss: 1.2775 - val_acc: 0.6413\n",
      "Epoch 73/100\n",
      "16793/16793 [==============================] - 8s 481us/step - loss: 0.6384 - acc: 0.8073 - val_loss: 1.2448 - val_acc: 0.6349\n",
      "Epoch 74/100\n",
      "16793/16793 [==============================] - 8s 478us/step - loss: 0.6429 - acc: 0.8093 - val_loss: 1.2775 - val_acc: 0.6531\n",
      "Epoch 75/100\n",
      "16793/16793 [==============================] - 8s 480us/step - loss: 0.6354 - acc: 0.8084 - val_loss: 1.2494 - val_acc: 0.6479\n",
      "Epoch 76/100\n",
      "16793/16793 [==============================] - 8s 481us/step - loss: 0.6253 - acc: 0.8131 - val_loss: 1.3160 - val_acc: 0.6392\n",
      "Epoch 77/100\n",
      "16793/16793 [==============================] - 8s 478us/step - loss: 0.6302 - acc: 0.8114 - val_loss: 1.3165 - val_acc: 0.6509\n",
      "Epoch 78/100\n",
      "16793/16793 [==============================] - 8s 480us/step - loss: 0.6222 - acc: 0.8137 - val_loss: 1.2967 - val_acc: 0.6433\n",
      "Epoch 79/100\n",
      "16793/16793 [==============================] - 8s 480us/step - loss: 0.6095 - acc: 0.8166 - val_loss: 1.3592 - val_acc: 0.6492\n",
      "Epoch 80/100\n",
      "16793/16793 [==============================] - 8s 479us/step - loss: 0.6130 - acc: 0.8193 - val_loss: 1.2892 - val_acc: 0.6522\n",
      "Epoch 81/100\n",
      "16793/16793 [==============================] - 8s 480us/step - loss: 0.5999 - acc: 0.8204 - val_loss: 1.3078 - val_acc: 0.6559\n",
      "Epoch 82/100\n",
      "16793/16793 [==============================] - 8s 481us/step - loss: 0.6004 - acc: 0.8199 - val_loss: 1.3355 - val_acc: 0.6556\n",
      "Epoch 83/100\n",
      "16793/16793 [==============================] - 8s 479us/step - loss: 0.5920 - acc: 0.8234 - val_loss: 1.3738 - val_acc: 0.6533\n",
      "Epoch 84/100\n",
      "16793/16793 [==============================] - 8s 480us/step - loss: 0.5967 - acc: 0.8222 - val_loss: 1.3172 - val_acc: 0.6520\n",
      "Epoch 85/100\n",
      "16793/16793 [==============================] - 8s 481us/step - loss: 0.5872 - acc: 0.8224 - val_loss: 1.3298 - val_acc: 0.6456\n",
      "Epoch 86/100\n",
      "16793/16793 [==============================] - 8s 479us/step - loss: 0.5900 - acc: 0.8222 - val_loss: 1.3294 - val_acc: 0.6588\n",
      "Epoch 87/100\n",
      "16793/16793 [==============================] - 8s 480us/step - loss: 0.5791 - acc: 0.8265 - val_loss: 1.3415 - val_acc: 0.6433\n",
      "Epoch 88/100\n",
      "16793/16793 [==============================] - 8s 481us/step - loss: 0.5834 - acc: 0.8267 - val_loss: 1.3353 - val_acc: 0.6336\n",
      "Epoch 89/100\n",
      "16793/16793 [==============================] - 8s 478us/step - loss: 0.5766 - acc: 0.8273 - val_loss: 1.3430 - val_acc: 0.6545\n",
      "Epoch 90/100\n",
      "16793/16793 [==============================] - 8s 480us/step - loss: 0.5674 - acc: 0.8296 - val_loss: 1.3587 - val_acc: 0.6511\n",
      "Epoch 91/100\n",
      "16793/16793 [==============================] - 8s 480us/step - loss: 0.5679 - acc: 0.8286 - val_loss: 1.3294 - val_acc: 0.6476\n",
      "Epoch 92/100\n",
      "16793/16793 [==============================] - 8s 479us/step - loss: 0.5650 - acc: 0.8289 - val_loss: 1.3071 - val_acc: 0.6368\n",
      "Epoch 93/100\n",
      "16793/16793 [==============================] - 8s 480us/step - loss: 0.5605 - acc: 0.8346 - val_loss: 1.3446 - val_acc: 0.6592\n",
      "Epoch 94/100\n",
      "16793/16793 [==============================] - 8s 481us/step - loss: 0.5735 - acc: 0.8295 - val_loss: 1.3688 - val_acc: 0.6481\n",
      "Epoch 95/100\n",
      "16793/16793 [==============================] - 8s 478us/step - loss: 0.5702 - acc: 0.8286 - val_loss: 1.3865 - val_acc: 0.6540\n",
      "Epoch 96/100\n",
      "16793/16793 [==============================] - 8s 480us/step - loss: 0.5600 - acc: 0.8296 - val_loss: 1.3708 - val_acc: 0.6586\n",
      "Epoch 97/100\n",
      "16793/16793 [==============================] - 8s 481us/step - loss: 0.5811 - acc: 0.8250 - val_loss: 1.3452 - val_acc: 0.6358\n",
      "Epoch 98/100\n",
      "16793/16793 [==============================] - 8s 479us/step - loss: 0.5633 - acc: 0.8308 - val_loss: 1.3988 - val_acc: 0.6534\n",
      "Epoch 99/100\n",
      "16793/16793 [==============================] - 8s 480us/step - loss: 0.5618 - acc: 0.8324 - val_loss: 1.3406 - val_acc: 0.6426\n",
      "Epoch 100/100\n",
      "16793/16793 [==============================] - 8s 480us/step - loss: 0.6174 - acc: 0.8191 - val_loss: 1.3722 - val_acc: 0.6383\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fbdd912d550>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Model.fit(XTrain, \n",
    "          YTrainDummy,\n",
    "          epochs=100,\n",
    "          validation_data=(XTest, YTestDummy),\n",
    "          batch_size=128,\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-07-02T10:14:13.646Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7704996129339606\n",
      "0.6382636655948553\n",
      "😊\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[   0,   11,    0,    0,   53,    0,   31,    9,    2,    0],\n",
       "       [   0,  119,    0,    0,   12,    1,  347,   47,    4,    0],\n",
       "       [   0,    3,    0,    0,    1,    1,   27,    2,    0,    0],\n",
       "       [   0,    5,    0,    1,    2,    4,   75,   29,    1,    0],\n",
       "       [   0,    7,    0,    0,  212,    0,   31,    5,    0,    0],\n",
       "       [   0,    2,    0,    3,    1,    6,   25,   10,    0,    0],\n",
       "       [   0,  102,    0,    5,   12,    6, 2362,  255,   20,    3],\n",
       "       [   0,   43,    0,    3,    7,    6,  560,  612,   18,    2],\n",
       "       [   0,    9,    0,    8,    2,    5,  116,   64,  259,    6],\n",
       "       [   0,    1,    0,    0,    0,    2,   11,    6,    2,    2]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f1_score(YTrainNum,Model.predict_classes(XTrain), average=\"micro\"))\n",
    "print(f1_score(YTestNum,Model.predict_classes(XTest), average=\"micro\"))\n",
    "print(\"😊\")\n",
    "confusion_matrix(YTestNum,Model.predict_classes(XTest))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
