{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-26T16:46:54.985660Z",
     "start_time": "2019-05-26T16:46:53.864000Z"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Produce List Of Dates For Webscrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-26T10:45:07.002728Z",
     "start_time": "2019-05-26T10:45:06.985970Z"
    }
   },
   "outputs": [],
   "source": [
    "DateList = []\n",
    "temp = datetime.date(1958,8,4)\n",
    "DateList.append(temp) \n",
    "while temp < datetime.date.today():\n",
    "    temp = temp + datetime.timedelta(days=7)\n",
    "    DateList.append(str(temp))\n",
    "print(DateList[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Function To Pull Charts Data & Organise In To Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-26T10:45:08.244152Z",
     "start_time": "2019-05-26T10:45:08.237898Z"
    }
   },
   "outputs": [],
   "source": [
    "def Scrape(Date,Website):\n",
    "    r=requests.get(str(Website))\n",
    "    Data = BeautifulSoup(r.text,\"html.parser\")\n",
    "    ArtistList = []\n",
    "    for i in Data.find_all(class_=\"chart-list-item__artist\"):\n",
    "        ArtistList.append(re.search(\".*(?=\\n\\s*</a>)|.*(?=[^</a>]</div>)\",str(i))[0])\n",
    "    TrackList = []\n",
    "    for i in Data.find_all(class_=\"chart-list-item__title-text\"):\n",
    "        TrackList.append(re.search(\".*(?=\\n*</span>)\",str(i))[0])\n",
    "    Output = pd.DataFrame({\"Track\": TrackList,\n",
    "                           \"Artist\": ArtistList,\n",
    "                           \"Rank\": list(range(1, len(TrackList)+1)),\n",
    "                           \"Date\": str(Date)})\n",
    "    return(Output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Function For All Dates & Store In List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-26T12:49:26.178792Z",
     "start_time": "2019-05-26T10:45:10.335492Z"
    }
   },
   "outputs": [],
   "source": [
    "DataFrameList = []\n",
    "for j, i in enumerate(DateList):\n",
    "    if(j%100==0):\n",
    "        print(str(j)+\" Out Of \",str(len(DateList)))\n",
    "    try:\n",
    "        DataFrameList.append(Scrape(str(i),\"https://www.billboard.com/charts/hot-100/\"+str(i)+\"/\"))\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Join All Data Frames Together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-26T12:56:58.285044Z",
     "start_time": "2019-05-26T12:53:41.676537Z"
    }
   },
   "outputs": [],
   "source": [
    "Data = DataFrameList[0]\n",
    "for j, i in enumerate(DataFrameList):\n",
    "    Data = pd.concat([Data,i])\n",
    "print(Data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create No Duplicate Song Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-26T12:57:18.020724Z",
     "start_time": "2019-05-26T12:57:17.800347Z"
    }
   },
   "outputs": [],
   "source": [
    "DataNoDups = Data[[\"Track\",\"Artist\"]].drop_duplicates(keep=\"first\")\n",
    "DataNoDups = DataNoDups.reset_index(drop = True)\n",
    "DataNoDups.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pull Lyrics For Unique Songs Where Possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-26T13:27:51.241891Z",
     "start_time": "2019-05-26T12:57:26.639217Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Lyrics = []\n",
    "for i, j in enumerate(DataNoDups.Track):\n",
    "    if(i%2000==0):\n",
    "        print(str(i)+\" Out Of \",str(len(DataNoDups.Track)))\n",
    "    try:\n",
    "        Website = \"http://api.chartlyrics.com/apiv1.asmx/SearchLyricDirect?artist=\"+str(DataNoDups.Artist[i])+\"&song=\"+str(DataNoDups.Track[i])\n",
    "        r = requests.get(Website)\n",
    "        Output = BeautifulSoup(r.text,\"html.parser\")\n",
    "        Output = str(Output.find_all(\"lyric\"))\n",
    "        Lyrics.append(re.search(\"(?<=<lyric>).*(?=</lyric>)\",Output,re.DOTALL)[0])\n",
    "    except:\n",
    "        Lyrics.append(\"Error\")\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Lyrics Lookup Table & Print Match Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-26T13:29:07.682472Z",
     "start_time": "2019-05-26T13:29:07.643760Z"
    }
   },
   "outputs": [],
   "source": [
    "print(len([Text for Text in Lyrics if len(Text) > 20]), \" - Rows With Lyrics\")\n",
    "DataNoDups[\"Lyrics\"] = Lyrics\n",
    "DataNoDups[\"Temp\"] = DataNoDups.Track + \" \" + DataNoDups.Artist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pull The Lyrics In To The Main Dataset And Print Match Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-26T13:29:21.597001Z",
     "start_time": "2019-05-26T13:29:21.058573Z"
    }
   },
   "outputs": [],
   "source": [
    "Data[\"Temp\"] = Data.Track + \" \" + Data.Artist\n",
    "Data = Data.merge(DataNoDups[[\"Temp\",\"Lyrics\"]], how = \"left\", on = \"Temp\")\n",
    "Data = Data.drop(columns = \"Temp\")\n",
    "print(len([Text for Text in Data.Lyrics if len(Text) > 20])/len(Data.Lyrics), \" - % Rows With Lyrics\")\n",
    "Data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create No Duplicates Artist Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-26T16:47:03.973802Z",
     "start_time": "2019-05-26T16:47:03.912948Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12029\n"
     ]
    }
   ],
   "source": [
    "ArtistData = list(Data[\"Artist\"].drop_duplicates())\n",
    "print(len(ArtistData))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pull Genres For Artists In"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-26T17:35:42.639834Z",
     "start_time": "2019-05-26T16:47:13.464780Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Out Of  12029\n",
      "1000 Out Of  12029\n",
      "2000 Out Of  12029\n",
      "3000 Out Of  12029\n",
      "4000 Out Of  12029\n",
      "5000 Out Of  12029\n",
      "6000 Out Of  12029\n",
      "7000 Out Of  12029\n",
      "8000 Out Of  12029\n",
      "9000 Out Of  12029\n",
      "10000 Out Of  12029\n",
      "11000 Out Of  12029\n",
      "12000 Out Of  12029\n"
     ]
    }
   ],
   "source": [
    "Genres = []\n",
    "for j, i in enumerate(ArtistData):\n",
    "    if(j%1000==0):\n",
    "        print(str(j)+\" Out Of \",str(len(ArtistData)))\n",
    "    try:\n",
    "        if(re.search(\"With\",i) !=None):\n",
    "            temp = re.search(\".*(?=With)\",i)[0]\n",
    "        elif(re.search(\"Feat\",i) !=None):\n",
    "            temp = re.search(\".*(?=Feat)\",i)[0]\n",
    "        elif(re.search(\",\",i) !=None):\n",
    "            temp = i.split(\",\")[0]\n",
    "        elif(re.search(\"&\",i) !=None):\n",
    "            temp = re.search(\".*(?=&)\",i)[0]\n",
    "        else:\n",
    "            temp = i\n",
    "        temp = temp.lstrip()\n",
    "        Website = \"https://www.allmusic.com/search/artists/\" + str(temp)\n",
    "        r = requests.get(Website,headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.102 Safari/537.36'})\n",
    "        Output = BeautifulSoup(r.text,\"html.parser\")\n",
    "        Output = str(Output.find_all(class_=\"genres\")[0])\n",
    "        Genres.append(re.search(\"(?<=>)\\s*.*(?=</)\",Output,re.MULTILINE)[0])\n",
    "    except:\n",
    "        Genres.append(\"Error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Genre Lookup Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-26T17:36:20.588557Z",
     "start_time": "2019-05-26T17:36:20.571878Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match Rate -  0.9695735306343004\n"
     ]
    }
   ],
   "source": [
    "ArtistData = pd.DataFrame({\"Artists\" : ArtistData})\n",
    "ArtistData[\"Genres\"] = Genres\n",
    "print(\"Match Rate - \", 1 -len(ArtistData.loc[ArtistData.Genres == \"Error\"])/len(ArtistData.Artists))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pull The Genre In To The Main Dataset And Print Match Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-26T18:03:44.140655Z",
     "start_time": "2019-05-26T18:03:43.588924Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9817103638129178  - % Rows With Genres\n"
     ]
    }
   ],
   "source": [
    "Data = Data.drop_duplicates()\n",
    "Data = Data.merge(ArtistData, how = \"left\", left_on=\"Artist\", right_on = \"Artists\").drop(columns = \"Artists\")\n",
    "print(len([Text for Text in Data.Genres if Text != \"Error\"])/len(Data.Genres), \" - % Rows With Genres\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-26T18:14:25.997941Z",
     "start_time": "2019-05-26T18:14:24.981064Z"
    }
   },
   "outputs": [],
   "source": [
    "GenresClean = []\n",
    "for j, i in enumerate(Data.Genres):\n",
    "    try:\n",
    "        GenresClean.append(re.search(\"(?<=\\n)\\s*\\w*/*\\w*\",str(i))[0])\n",
    "    except:\n",
    "        GenresClean.append(\"Error\")\n",
    "GenresClean = [Text.strip(' ') for Text in GenresClean]\n",
    "GenresClean = np.where(np.array(GenresClean) == \"R\",\"R&B\",GenresClean)\n",
    "Data[\"GenresClean\"] = GenresClean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-26T18:17:17.963337Z",
     "start_time": "2019-05-26T18:17:14.042976Z"
    }
   },
   "outputs": [],
   "source": [
    "LyricsClean = []\n",
    "for i in Data.Lyrics:\n",
    "    try:\n",
    "        temp = i.replace(\"\\r\",\" \")\n",
    "        temp = temp.replace(\"\\n\",\" \")\n",
    "        temp = temp.replace(\"\\\\\",\" \")\n",
    "        temp = temp.replace(\"   \", \" \")\n",
    "        temp = temp.replace(\"  \", \" \")\n",
    "        LyricsClean.append(temp)\n",
    "    except:\n",
    "        LyricsClean.append(\"Error\")\n",
    "Data[\"LyricsClean\"] = LyricsClean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preview Output And Export As CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-26T18:25:23.208165Z",
     "start_time": "2019-05-26T18:25:23.042301Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9817 - Genre Match Rate\n",
      "0.699 - Lyrics Match Rate\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Track</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Rank</th>\n",
       "      <th>Date</th>\n",
       "      <th>GenresClean</th>\n",
       "      <th>LyricsClean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Poor Little Fool</td>\n",
       "      <td>Ricky Nelson</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1958-08-04</td>\n",
       "      <td>Pop/Rock</td>\n",
       "      <td>I used to play around with hearts that hastene...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Patricia</td>\n",
       "      <td>Perez Prado And His Orchestra</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1958-08-04</td>\n",
       "      <td>Latin</td>\n",
       "      <td>Instrumental, NO LYRICS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Splish Splash</td>\n",
       "      <td>Bobby Darin</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1958-08-04</td>\n",
       "      <td>Pop/Rock</td>\n",
       "      <td>splish splash I was taking a bath long about a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hard Headed Woman</td>\n",
       "      <td>Elvis Presley With The Jordanaires</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1958-08-04</td>\n",
       "      <td>Pop/Rock</td>\n",
       "      <td>Well a hard headed woman, A soft hearted man B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>When</td>\n",
       "      <td>Kalin Twins</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1958-08-04</td>\n",
       "      <td>Pop/Rock</td>\n",
       "      <td>Error</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Track                              Artist  Rank        Date  \\\n",
       "0   Poor Little Fool                        Ricky Nelson   1.0  1958-08-04   \n",
       "1           Patricia       Perez Prado And His Orchestra   2.0  1958-08-04   \n",
       "2      Splish Splash                         Bobby Darin   3.0  1958-08-04   \n",
       "3  Hard Headed Woman  Elvis Presley With The Jordanaires   4.0  1958-08-04   \n",
       "4               When                         Kalin Twins   5.0  1958-08-04   \n",
       "\n",
       "  GenresClean                                        LyricsClean  \n",
       "0    Pop/Rock  I used to play around with hearts that hastene...  \n",
       "1       Latin                            Instrumental, NO LYRICS  \n",
       "2    Pop/Rock  splish splash I was taking a bath long about a...  \n",
       "3    Pop/Rock  Well a hard headed woman, A soft hearted man B...  \n",
       "4    Pop/Rock                                              Error  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CleanData = Data.drop(columns = [\"Lyrics\",\"Genres\"])\n",
    "CleanData.to_csv(\"CleanData.csv\")\n",
    "print(str(round(len(CleanData.loc[CleanData.GenresClean != \"Error\"])/len(CleanData),4)) + \" - Genre Match Rate\")\n",
    "print(str(round(len(CleanData.loc[CleanData.LyricsClean != \"Error\"])/len(CleanData),4)) +\" - Lyrics Match Rate\")\n",
    "CleanData.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
